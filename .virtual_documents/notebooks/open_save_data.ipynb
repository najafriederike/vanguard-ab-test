import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

%matplotlib inline


df_final_demo = pd.read_csv('../data/raw/df_final_demo.txt', sep=',')  
df_final_demo.head()


df_final_exp_clients = pd.read_csv('../data/raw/df_final_experiment_clients.txt', sep=',')  
df_final_exp_clients.head()


df_final_web_data_pt1 = pd.read_csv('../data/raw/df_final_web_data_pt_1.txt', sep=',')  
df_final_web_data_pt1.head()


df_final_web_data_pt2 = pd.read_csv('../data/raw/df_final_web_data_pt_2.txt', sep=',')  
df_final_web_data_pt2.head()


df_final_exp_clients.to_csv('../data/clean/df_final_exp_clients.csv', index=False)
df_final_demo.to_csv('../data/clean/df_final_demo.csv', index=False)
df_final_web_data_pt2.to_csv('../data/clean/df_final_web_data_pt2.csv', index=False)
df_final_web_data_pt1.to_csv('../data/clean/df_final_web_data_pt1.csv', index=False)


# Load the two parts of the final web data
file_path_pt1 = '../data/clean/df_final_web_data_pt1.csv'
file_path_pt2 = '../data/clean/df_final_web_data_pt2.csv'

df_pt1 = pd.read_csv(file_path_pt1)
df_pt2 = pd.read_csv(file_path_pt2)

# Merge the two parts into one dataframe
df_final_web_data_merged = pd.concat([df_pt1, df_pt2], ignore_index=True)

# Display the structure of the final web data merged dataframe
df_final_web_data_merged.head()


# Save the final web data merged dataframe
df_final_web_data_merged.to_csv('../data/clean/df_final_web_data_merged.csv', index=False)


#Start of cleaning
# Reload the datasets
df_demo = pd.read_csv('../data/clean/df_final_demo.csv')
df_exp_clients = pd.read_csv('../data/clean/df_final_exp_clients.csv')
df_web_data = pd.read_csv('../data/clean/df_final_web_data_merged.csv')

# Initial inspection of the datasets for missing values and data types
df_demo_info = df_demo.info()
df_demo_missing = df_demo.isnull().sum()

df_exp_clients_info = df_exp_clients.info()
df_exp_clients_missing = df_exp_clients.isnull().sum()

df_web_data_info = df_web_data.info()
df_web_data_missing = df_web_data.isnull().sum()

(df_demo_info, df_demo_missing, df_exp_clients_info, df_exp_clients_missing, df_web_data_info, df_web_data_missing)



# Initial inspection of the datasets for missing values and data types
df_demo_info = df_demo.info()
df_demo_missing = df_demo.isnull().sum()
df_demo_missing


df_exp_clients_info = df_exp_clients.info()
df_exp_clients_missing = df_exp_clients.isnull().sum()
df_exp_clients_missing


df_web_data_info = df_web_data.info()
df_web_data_missing = df_web_data.isnull().sum()
df_web_data_missing


#drop rows with missing values in tenure, age, gender
df_demo_cleaned = df_demo.dropna(subset=['clnt_tenure_yr', 'clnt_tenure_mnth', 'clnt_age', 'gendr'])


df_demo_cleaned.info()


df_demo_cleaned_missing = df_demo_cleaned.isnull().sum()

df_demo_cleaned_missing


#drop row with null variation
df_exp_clients_cleaned = df_exp_clients.dropna(subset=['Variation'])


df_exp_clients_cleaned.isnull().sum()



#convert date_time column from string to date format
df_web_data['date_time'] = pd.to_datetime(df_web_data['date_time'])


df_web_data.info()


# Mergeing Cleaned Data based on client_id into one csv
# Merge demographic and experiment data
df_merged = pd.merge(df_demo_cleaned, df_exp_clients_cleaned, on='client_id', how='inner')

# Merge the result with web data
df_final = pd.merge(df_merged, df_web_data, on='client_id', how='inner')


# Verify the merged dataset
df_final_info = df_final.info()
df_final_missing = df_final.isnull().sum()

(df_final_info, df_final_missing)


# Save the merged cleaned dataset
df_final.to_csv('../data/clean/df_final.csv', index=False)



